{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1fe21620",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'search_jobs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 153\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;66;03m# ============================================================\u001b[39;00m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;66;03m# Example: run bias measurement on text queries\u001b[39;00m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;66;03m# ============================================================\u001b[39;00m\n\u001b[1;32m    138\u001b[0m text_queries \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    139\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSenior machine learning engineer with python\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    140\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEntry level data analyst with SQL and Excel\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    150\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmachine learning engineer with SQL\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    151\u001b[0m ]\n\u001b[0;32m--> 153\u001b[0m bias_summary_text, per_query_detail \u001b[38;5;241m=\u001b[39m measure_exposure_bias_text_queries(\n\u001b[1;32m    154\u001b[0m     queries\u001b[38;5;241m=\u001b[39mtext_queries,\n\u001b[1;32m    155\u001b[0m     top_k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m,\n\u001b[1;32m    156\u001b[0m )\n",
      "Cell \u001b[0;32mIn[3], line 37\u001b[0m, in \u001b[0;36mmeasure_exposure_bias_text_queries\u001b[0;34m(queries, top_k)\u001b[0m\n\u001b[1;32m     34\u001b[0m per_query_exposure \u001b[38;5;241m=\u001b[39m []  \u001b[38;5;66;03m# for per-query plot\u001b[39;00m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m q \u001b[38;5;129;01min\u001b[39;00m queries:\n\u001b[0;32m---> 37\u001b[0m     recs \u001b[38;5;241m=\u001b[39m search_jobs(q, top_k\u001b[38;5;241m=\u001b[39mtop_k)\n\u001b[1;32m     39\u001b[0m     \u001b[38;5;66;03m# search_jobs already drops 'unknown', but we guard anyway\u001b[39;00m\n\u001b[1;32m     40\u001b[0m     recs_valid \u001b[38;5;241m=\u001b[39m recs[recs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompany_size_group\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munknown\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mcopy()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'search_jobs' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import joblib\n",
    "\n",
    "# ============================================================\n",
    "# Bias measurement based on TEXT QUERIES using search_jobs()\n",
    "# ============================================================\n",
    "df, X_hybrid = joblib.load(\"../data/hybrid_embeddings.pkl\")\n",
    "\n",
    "def measure_exposure_bias_text_queries(queries, top_k=20):\n",
    "    \"\"\"\n",
    "    Measure exposure bias using text-based recommendations.\n",
    "\n",
    "    For each query in `queries`:\n",
    "      - call search_jobs(query, top_k)\n",
    "      - count how many small/medium/large company jobs appear\n",
    "    Then:\n",
    "      - compare exposure distribution to dataset distribution\n",
    "      - return summary DataFrame\n",
    "    \"\"\"\n",
    "\n",
    "    # ---- 1. Dataset-level distribution (exclude 'unknown') ----\n",
    "    df_valid = df[df[\"company_size_group\"] != \"unknown\"].copy()\n",
    "\n",
    "    dataset_counts = (\n",
    "        df_valid[\"company_size_group\"]\n",
    "        .value_counts()\n",
    "        .sort_index()\n",
    "    )\n",
    "    dataset_share = dataset_counts / dataset_counts.sum()\n",
    "\n",
    "    # ---- 2. Aggregate exposure across all queries ----\n",
    "    exposure_counts = {}\n",
    "    per_query_exposure = []  # for per-query plot\n",
    "\n",
    "    for q in queries:\n",
    "        recs = search_jobs(q, top_k=top_k)\n",
    "\n",
    "        # search_jobs already drops 'unknown', but we guard anyway\n",
    "        recs_valid = recs[recs[\"company_size_group\"] != \"unknown\"].copy()\n",
    "\n",
    "        counts = recs_valid[\"company_size_group\"].value_counts()\n",
    "        exposure_counts_for_q = {\n",
    "            \"query\": q,\n",
    "            \"small\": counts.get(\"small\", 0),\n",
    "            \"medium\": counts.get(\"medium\", 0),\n",
    "            \"large\": counts.get(\"large\", 0),\n",
    "        }\n",
    "        per_query_exposure.append(exposure_counts_for_q)\n",
    "\n",
    "        for group, c in counts.items():\n",
    "            exposure_counts[group] = exposure_counts.get(group, 0) + c\n",
    "\n",
    "    # Convert overall exposure to shares\n",
    "    exposure_series = pd.Series(exposure_counts).sort_index()\n",
    "    total_recs = exposure_series.sum()\n",
    "    exposure_share = exposure_series / total_recs\n",
    "\n",
    "    # ---- 3. Build summary table (overall) ----\n",
    "    groups = [\"small\", \"medium\", \"large\"]\n",
    "    rows = []\n",
    "    for g in groups:\n",
    "        ds = float(dataset_share.get(g, 0.0))\n",
    "        es = float(exposure_share.get(g, 0.0))\n",
    "        ratio = es / ds if ds > 0 else np.nan\n",
    "        rows.append({\n",
    "            \"company_size_group\": g,\n",
    "            \"dataset_share\": ds,\n",
    "            \"exposure_share\": es,\n",
    "            \"exposure_ratio\": ratio,\n",
    "        })\n",
    "\n",
    "    summary = pd.DataFrame(rows)\n",
    "\n",
    "    print(\"\\n=== Text-Query Based Exposure Bias Summary ===\")\n",
    "    print(summary.to_string(index=False))\n",
    "\n",
    "    # ---- 4. Overall bar plot: dataset vs exposure ----\n",
    "    x = np.arange(len(summary))\n",
    "    width = 0.35\n",
    "\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    plt.bar(x - width/2, summary[\"dataset_share\"], width, label=\"Dataset share\")\n",
    "    plt.bar(x + width/2, summary[\"exposure_share\"], width, label=\"Exposure share (recs)\")\n",
    "\n",
    "    plt.xticks(x, summary[\"company_size_group\"])\n",
    "    plt.ylabel(\"Proportion\")\n",
    "    plt.title(f\"Dataset vs Recommendation Exposure (top-{top_k}, text queries)\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # ---- 5. Per-query stacked bar plot ----\n",
    "    per_query_df = pd.DataFrame(per_query_exposure)\n",
    "\n",
    "    # Normalize per query to proportions\n",
    "    per_query_df[\"total\"] = per_query_df[[\"small\", \"medium\", \"large\"]].sum(axis=1)\n",
    "    for g in groups:\n",
    "        per_query_df[g + \"_share\"] = np.where(\n",
    "            per_query_df[\"total\"] > 0,\n",
    "            per_query_df[g] / per_query_df[\"total\"],\n",
    "            0.0,\n",
    "        )\n",
    "\n",
    "    # Shorten query labels for plotting\n",
    "    per_query_df[\"query_label\"] = per_query_df[\"query\"].str.slice(0, 25) + np.where(\n",
    "        per_query_df[\"query\"].str.len() > 25, \"...\", \"\"\n",
    "    )\n",
    "\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    bottom = np.zeros(len(per_query_df))\n",
    "    colors = {\"small\": \"tab:blue\", \"medium\": \"tab:orange\", \"large\": \"tab:green\"}\n",
    "\n",
    "    for g in groups:\n",
    "        plt.bar(\n",
    "            per_query_df[\"query_label\"],\n",
    "            per_query_df[g + \"_share\"],\n",
    "            bottom=bottom,\n",
    "            label=g,\n",
    "            color=colors[g],\n",
    "        )\n",
    "        bottom += per_query_df[g + \"_share\"].values\n",
    "\n",
    "    plt.xticks(rotation=45, ha=\"right\")\n",
    "    plt.ylabel(\"Proportion in top-k\")\n",
    "    plt.title(f\"Per-Query Exposure by Company Size Group (top-{top_k})\")\n",
    "    plt.legend(title=\"Company Size Group\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    return summary, per_query_df\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Example: run bias measurement on text queries\n",
    "# ============================================================\n",
    "\n",
    "text_queries = [\n",
    "    \"Senior machine learning engineer with python\",\n",
    "    \"Entry level data analyst with SQL and Excel\",\n",
    "    \"Remote data scientist role with python\",\n",
    "    \"Senior data engineer with spark and aws\",\n",
    "    \n",
    "    # \"Business intelligence analyst with tableau\",\n",
    "    # \"NLP research scientist with transformers\",\n",
    "    \"MLOps engineer with kubernetes and docker\",\n",
    "    # \"Computer vision engineer with pytorch\",\n",
    "    \"Analytics manager with leadership experience\",\n",
    "    \"Intern data science role with basic python\",\n",
    "    \"machine learning engineer with SQL\",\n",
    "]\n",
    "\n",
    "bias_summary_text, per_query_detail = measure_exposure_bias_text_queries(\n",
    "    queries=text_queries,\n",
    "    top_k=20,\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
